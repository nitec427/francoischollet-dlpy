{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_dir = pathlib.Path(\"train\")\n",
    "new_dir = pathlib.Path(\"cats_dogs\")\n",
    "import shutil\n",
    "def make_subset(subset_name, start, end):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        filenames = [f\"{category}.{i}.jpg\" for i in range(start, end)]\n",
    "        \n",
    "        for f_name in filenames:\n",
    "            shutil.copyfile(src = org_dir / f_name, dst = dir / f_name)\n",
    "\n",
    "make_subset(\"train\", 0, 1000)\n",
    "make_subset(\"validation\", 1000, 1500)\n",
    "make_subset(\"test\", 1500, 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import keras\n",
    "inputs = keras.Input(shape=(180,180,3))\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(.1),\n",
    "    layers.RandomZoom(.2),\n",
    "])\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "x = layers.Conv2D(filters = 32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2) (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(filters = 64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters = 128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters = 256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters = 256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_3 (Rescaling)     (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 178, 178, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 89, 89, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 87, 87, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 43, 43, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 41, 41, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 18, 18, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 9, 9, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 12545     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 991,041\n",
      "Trainable params: 991,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing with Keras\n",
    "\n",
    "Keras comes with image_dataset_from_directory function to easily prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_dir / \"train\", image_size = (180,180), batch_size = 32\n",
    ")\n",
    "\n",
    "validation_set = image_dataset_from_directory(\n",
    "    new_dir / \"validation\", image_size = (180,180), batch_size = 32\n",
    ")\n",
    "\n",
    "test_set = image_dataset_from_directory(\n",
    "    new_dir / \"test\", image_size = (180,180), batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preprocessing step generates tf.Data.Dataset from image files in a directory, like PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Dataset object is an iterator, for loop can be used to extract data. Typically, it returns batches of input data and labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape:  (32, 180, 180, 3)\n",
      "Labels batch shape:  (32,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_dataset:\n",
    "    print(\"Data batch shape: \", data_batch.shape)\n",
    "    print(\"Labels batch shape: \", labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit the model on dataset, **validation set** will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint(filepath=\"convnet_from_stratch.keras\", save_best_only=True, monitor = \"val_loss\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 42s 659ms/step - loss: 0.7345 - accuracy: 0.5060 - val_loss: 0.6928 - val_accuracy: 0.5010\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 40s 638ms/step - loss: 0.6986 - accuracy: 0.5180 - val_loss: 0.7890 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 41s 652ms/step - loss: 0.7048 - accuracy: 0.5515 - val_loss: 0.8431 - val_accuracy: 0.5390\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 41s 651ms/step - loss: 0.6483 - accuracy: 0.6235 - val_loss: 0.7160 - val_accuracy: 0.5420\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 40s 634ms/step - loss: 0.6128 - accuracy: 0.6565 - val_loss: 0.6295 - val_accuracy: 0.6260\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 40s 636ms/step - loss: 0.5886 - accuracy: 0.6900 - val_loss: 0.8040 - val_accuracy: 0.6040\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 40s 637ms/step - loss: 0.5496 - accuracy: 0.7210 - val_loss: 0.6002 - val_accuracy: 0.6890\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 42s 662ms/step - loss: 0.5107 - accuracy: 0.7560 - val_loss: 0.5805 - val_accuracy: 0.7030\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 47s 738ms/step - loss: 0.4790 - accuracy: 0.7880 - val_loss: 0.6509 - val_accuracy: 0.7030\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 49s 772ms/step - loss: 0.4311 - accuracy: 0.8090 - val_loss: 0.5570 - val_accuracy: 0.7350\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 44s 692ms/step - loss: 0.3864 - accuracy: 0.8245 - val_loss: 0.6066 - val_accuracy: 0.7090\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 45s 715ms/step - loss: 0.3326 - accuracy: 0.8595 - val_loss: 0.6390 - val_accuracy: 0.7350\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 43s 688ms/step - loss: 0.2859 - accuracy: 0.8775 - val_loss: 0.7115 - val_accuracy: 0.7260\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 44s 692ms/step - loss: 0.2389 - accuracy: 0.9015 - val_loss: 0.8056 - val_accuracy: 0.7260\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 44s 703ms/step - loss: 0.1806 - accuracy: 0.9270 - val_loss: 0.7742 - val_accuracy: 0.7340\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 40s 637ms/step - loss: 0.1482 - accuracy: 0.9365 - val_loss: 0.9092 - val_accuracy: 0.7340\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 41s 650ms/step - loss: 0.1118 - accuracy: 0.9565 - val_loss: 1.1189 - val_accuracy: 0.7360\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 40s 636ms/step - loss: 0.0956 - accuracy: 0.9660 - val_loss: 1.2883 - val_accuracy: 0.6980\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 41s 643ms/step - loss: 0.0951 - accuracy: 0.9635 - val_loss: 1.4246 - val_accuracy: 0.7390\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 40s 638ms/step - loss: 0.0756 - accuracy: 0.9710 - val_loss: 1.4718 - val_accuracy: 0.7400\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 43s 676ms/step - loss: 0.0671 - accuracy: 0.9775 - val_loss: 1.5873 - val_accuracy: 0.7270\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 42s 659ms/step - loss: 0.0492 - accuracy: 0.9825 - val_loss: 1.9369 - val_accuracy: 0.7030\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 41s 650ms/step - loss: 0.0649 - accuracy: 0.9800 - val_loss: 1.7539 - val_accuracy: 0.7220\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 44s 693ms/step - loss: 0.0642 - accuracy: 0.9770 - val_loss: 1.5881 - val_accuracy: 0.7430\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 40s 633ms/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 1.8417 - val_accuracy: 0.7200\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 44s 699ms/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 1.7441 - val_accuracy: 0.7470\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 42s 671ms/step - loss: 0.0545 - accuracy: 0.9825 - val_loss: 2.8235 - val_accuracy: 0.6660\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 42s 659ms/step - loss: 0.1631 - accuracy: 0.9805 - val_loss: 1.9413 - val_accuracy: 0.7370\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 41s 657ms/step - loss: 0.0175 - accuracy: 0.9965 - val_loss: 2.3946 - val_accuracy: 0.7340\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 41s 658ms/step - loss: 0.0675 - accuracy: 0.9755 - val_loss: 2.3465 - val_accuracy: 0.7460\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "train_dataset,\n",
    "epochs=30,\n",
    "validation_data=validation_set,\n",
    "callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy  = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy, \"bo\", label = \"Training Accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label = \"Validation Accuracy\" )\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation\n",
    "\n",
    "When you have few training samples, better to use Data Augmentation. You may also reduce overfitting by using weight decay (L2 Regularization) or dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging PreTrained Model\n",
    "\n",
    "On small image datasets, using pretrained models performs well. There are two ways to use a pretrained model: Feature Extraction and Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 9s 136ms/step - loss: 0.5588 - accuracy: 0.7445\n",
      "Acc: 0.7444999814033508 \n"
     ]
    }
   ],
   "source": [
    "test_model = keras.models.load_model(\"convnet_from_stratch.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_set)\n",
    "print(f\"Acc: {test_acc} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
