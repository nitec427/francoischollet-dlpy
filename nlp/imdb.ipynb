{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0   479k      0  0:02:51  0:02:51 --:--:-- 2024k22.0M    0     0   368k      0  0:03:43  0:01:01  0:02:42  409k.2M   76 61.1M    0     0   411k      0  0:03:19  0:02:32  0:00:47  610k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
     ]
    }
   ],
   "source": [
    "!cat aclImdb/train/pos/4077_10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir/category)\n",
    "    random.Random(1337).shuffle(files)\n",
    "    num_val_samples = int(0.2 * len(files))\n",
    "    val_files = files[-num_val_samples:]\n",
    "    for file_name in val_files:\n",
    "        shutil.move(train_dir / category / file_name, val_dir / category / file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 13:04:19.055470: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-09-08 13:04:19.055508: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: nitec-ABRA-A5-V15-2\n",
      "2022-09-08 13:04:19.055516: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: nitec-ABRA-A5-V15-2\n",
      "2022-09-08 13:04:19.055609: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.65.1\n",
      "2022-09-08 13:04:19.055630: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.65.1\n",
      "2022-09-08 13:04:19.055635: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.65.1\n",
      "2022-09-08 13:04:19.055974: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import text_dataset_from_directory\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = text_dataset_from_directory(\n",
    "    \"aclImdb/train\", batch_size=batch_size\n",
    ")\n",
    "val_ds = text_dataset_from_directory(\n",
    "    \"aclImdb/val\", batch_size=batch_size\n",
    ")\n",
    "test_ds = text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape (32,)\n",
      "inputs.dtype <dtype: 'string'>\n",
      "targets.shape (32,)\n",
      "targets.dtype <dtype: 'int32'>\n",
      "inputs[0] tf.Tensor(b'My abiding love of Italian actress Lucianna Paluzzi, who helped jump-start my puberty with her performance in 1965\\'s \"Thunderball,\" has led me to some fairly unusual places. Case in point, this British curiosity from 1959, \"Carlton-Browne of the F.O.,\" which features Lucianna in one of her earlier roles. She plays a princess in this one, although the picture is actually a showcase for the talents of Terry-Thomas and Peter Sellers, both of whose stars were certainly on the rise at this point. In this cute, often very funny film, we learn of the Madeira-like island nation of Gaillardia, which had been a British colony until 1916 and then universally forgotten. Forty-three years later, however, it becomes the center of worldwide attention and international espionage when valuable cobalt deposits are discovered there, and Her Majesty sends the bumbling Carlton-Browne of the Foreign Office to take charge. Terry-Thomas underplays this part nicely, as does Sellers in his role as Prime Minister Amphibulos of the tiny country. (This was Sellers\\' second film of 1959 concerning a tiny country matching wits with the world, the other being \"The Mouse That Roared,\" of course.) Ian Bannen almost steals the show here as Gaillardia\\'s suave king, and my girl Lucianna is as appealing as can be in her minor role. The film exhibits much in the way of very dry humor, although there ARE some belly laughs to be had (the reception at the Gaillardian airport, for example, and especially that May Day-style parade of Gaillardian strength). And Sellers\\' seedy prime minister, with his cracked English and seemingly perpetual sweat stains, is yet another memorable character in this great actor\\'s pantheon. Despite the occasional instance or two of indecipherable, stiff-upper-lip British gibberish, I found this picture to be a winningly modest entertainment, and well presented on this crisp-looking Anchor Bay DVD.', shape=(), dtype=string)\n",
      "targets[0] tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs,targets in train_ds:\n",
    "    print(\"inputs.shape\", inputs.shape)\n",
    "    print(\"inputs.dtype\", inputs.dtype)\n",
    "    print(\"targets.shape\", targets.shape)\n",
    "    print(\"targets.dtype\", targets.dtype)\n",
    "    print(\"inputs[0]\", inputs[0])\n",
    "    print(\"targets[0]\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization\n",
    "text_vectorization = TextVectorization(\n",
    "    max_tokens= 20000, output_mode='multi_hot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only_train_ds = train_ds.map(lambda x, y:x)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "binary_1gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "\n",
    "binary_1gram_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "binary_1gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "def get_model(max_tokens:int = 20000, hidden_dim: int = 16):\n",
    "    inputs = keras.Input(shape=(max_tokens,))\n",
    "    x = layers.Dense(hidden_dim, activation='relu')(inputs)\n",
    "    x =  layers.Dropout(.5)(x)\n",
    "    \n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = \"accuracy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,033\n",
      "Trainable params: 320,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.4177 - accuracy: 0.8220 - val_loss: 0.2872 - val_accuracy: 0.8870\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 189s 298ms/step - loss: 0.2912 - accuracy: 0.8963 - val_loss: 0.2815 - val_accuracy: 0.8932\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.2630 - accuracy: 0.9110 - val_loss: 0.2852 - val_accuracy: 0.8908\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2440 - accuracy: 0.9180 - val_loss: 0.3023 - val_accuracy: 0.8880\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2395 - accuracy: 0.9219 - val_loss: 0.3110 - val_accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2342 - accuracy: 0.9222 - val_loss: 0.3216 - val_accuracy: 0.8874\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2261 - accuracy: 0.9281 - val_loss: 0.3269 - val_accuracy: 0.8896\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2245 - accuracy: 0.9286 - val_loss: 0.3388 - val_accuracy: 0.8854\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2223 - accuracy: 0.9306 - val_loss: 0.3496 - val_accuracy: 0.8800\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2200 - accuracy: 0.9309 - val_loss: 0.3554 - val_accuracy: 0.8842\n",
      "782/782 [==============================] - 22s 19ms/step - loss: 0.2961 - accuracy: 0.8866\n",
      "Test acc: 0.887\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(binary_1gram_train_ds.cache(), validation_data=binary_1gram_val_ds.cache(), epochs = 10, callbacks = callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"binary_1gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextVectorization can also be applied to N-grams\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    ngrams= 2,\n",
    "    max_tokens=20000,\n",
    "    output_mode='multi_hot',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization.adapt(text_only_train_ds)\n",
    "binary_2gram_train_ds = train_ds.map(lambda x,y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "binary_2gram_val_ds = val_ds.map(lambda x,y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "binary_2gram_test_ds = test_ds.map(lambda x,y: (text_vectorization(x), y), num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,033\n",
      "Trainable params: 320,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 173s 277ms/step - loss: 0.3759 - accuracy: 0.8443 - val_loss: 0.2677 - val_accuracy: 0.8918\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2417 - accuracy: 0.9159 - val_loss: 0.2753 - val_accuracy: 0.8936\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2047 - accuracy: 0.9336 - val_loss: 0.2940 - val_accuracy: 0.8996\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1965 - accuracy: 0.9398 - val_loss: 0.3075 - val_accuracy: 0.8976\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1953 - accuracy: 0.9463 - val_loss: 0.3146 - val_accuracy: 0.8966\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1846 - accuracy: 0.9483 - val_loss: 0.3296 - val_accuracy: 0.8940\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1783 - accuracy: 0.9510 - val_loss: 0.3440 - val_accuracy: 0.8960\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1788 - accuracy: 0.9513 - val_loss: 0.3524 - val_accuracy: 0.8930\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1787 - accuracy: 0.9525 - val_loss: 0.3574 - val_accuracy: 0.8894\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1689 - accuracy: 0.9540 - val_loss: 0.3615 - val_accuracy: 0.8870\n",
      "782/782 [==============================] - 13s 12ms/step - loss: 0.2691 - accuracy: 0.8968\n",
      "Test acc: 0.897\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(binary_2gram_train_ds.cache(), validation_data=binary_2gram_val_ds.cache(), epochs = 10, callbacks = callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"binary_2gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "639c7e9bf1b3b4c874b8fbde761d747f8f2092c6f55853bd9cc960bd675be475"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
